{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf25f0b-1ff7-4858-bd07-90c361698e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "082c87ca-9bbd-4d71-b58d-e64df507f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###CONSTANTS\n",
    "# IMAGE_SIZE=(224, 224)\n",
    "# VAL_FRACTION=0.05\n",
    "# SEQ_LENGTH=100\n",
    "# BATCH_SIZE=64\n",
    "# EPOCHS=20\n",
    "# AUTOTUNE=tf.data.AUTOTUNE\n",
    "# ###\n",
    "from train_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c7013eb-9741-4a79-8a52-c56079932d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>0</td>\n",
       "      <td>Several men in hard hats are operating a gian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>1</td>\n",
       "      <td>Workers look down from up above on a piece of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men working on a machine wearing hard hats .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>3</td>\n",
       "      <td>Four men on top of a tall structure .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>4</td>\n",
       "      <td>Three men on a large rig .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name comment_number  \\\n",
       "0  data/flickr30k_images/flickr30k_images//100009...              0   \n",
       "1  data/flickr30k_images/flickr30k_images//100009...              1   \n",
       "2  data/flickr30k_images/flickr30k_images//100009...              2   \n",
       "3  data/flickr30k_images/flickr30k_images//100009...              3   \n",
       "4  data/flickr30k_images/flickr30k_images//100009...              4   \n",
       "5  data/flickr30k_images/flickr30k_images//100024...              0   \n",
       "6  data/flickr30k_images/flickr30k_images//100024...              1   \n",
       "7  data/flickr30k_images/flickr30k_images//100024...              2   \n",
       "8  data/flickr30k_images/flickr30k_images//100024...              3   \n",
       "9  data/flickr30k_images/flickr30k_images//100024...              4   \n",
       "\n",
       "                                             comment  \n",
       "0   Two young guys with shaggy hair look at their...  \n",
       "1   Two young , White males are outside near many...  \n",
       "2   Two men in green shirts are standing in a yard .  \n",
       "3       A man in a blue shirt standing in a garden .  \n",
       "4            Two friends enjoy time spent together .  \n",
       "5   Several men in hard hats are operating a gian...  \n",
       "6   Workers look down from up above on a piece of...  \n",
       "7   Two men working on a machine wearing hard hats .  \n",
       "8              Four men on top of a tall structure .  \n",
       "9                         Three men on a large rig .  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df = pd.read_csv(os.path.join(DATA_PATH, \"results.csv\"), sep=\"|\").dropna()\n",
    "captionings_df.columns = [\"image_name\", \"comment_number\", \"comment\"]\n",
    "captionings_df[\"image_name\"] = IMAGES_PATH + \"/\" + captionings_df[\"image_name\"] \n",
    "\n",
    "captionings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c95baeec-74d0-4fc8-b3b5-6699622c7843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    158914.000000\n",
       "mean         65.198894\n",
       "std          26.869503\n",
       "min           8.000000\n",
       "25%          47.000000\n",
       "50%          60.000000\n",
       "75%          77.000000\n",
       "max         407.000000\n",
       "Name: comment, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df[\"comment\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39a62da3-6f36-4731-a93d-b5ce7b56b179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158914 entries, 0 to 158914\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   image_name      158914 non-null  object\n",
      " 1   comment_number  158914 non-null  object\n",
      " 2   comment         158914 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "captionings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d771d6ce-2273-44f4-b126-075ec2e7d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image-text examples:  150968\n",
      "Validation image-text examples:  7946\n"
     ]
    }
   ],
   "source": [
    "#Shuffle df\n",
    "captionings_df = captionings_df.sample(frac=1,\n",
    "                                       random_state=42,\n",
    "                                       replace=False,\n",
    "                                       )\n",
    "\n",
    "\n",
    "n_train_examples = int(len(captionings_df) * (1 - VAL_FRACTION))\n",
    "\n",
    "train_captionings_df = captionings_df[ : n_train_examples]\n",
    "val_captionings_df = captionings_df[n_train_examples : ]\n",
    "\n",
    "print(\"Train image-text examples: \", train_captionings_df.shape[0])\n",
    "print(\"Validation image-text examples: \", val_captionings_df.shape[0])\n",
    "\n",
    "#save splits\n",
    "train_captionings_df.to_csv(\"splits/train_captions.csv\", index=False)\n",
    "val_captionings_df.to_csv(\"splits/val_captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df08370b-1702-49b0-a088-5daf0d370e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'comment_number', 'comment'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captionings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a0d8b-46e4-487f-a6b5-ee1aad6a5a7c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b00cde8-3dbf-4ba0-a4b2-be49151f08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import build_tokenizer, build_image_augmenter,  decode_and_resize\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer()\n",
    "tokenizer.adapt(train_captionings_df[\"comment\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae11e236-e0ca-47d0-91de-8a5f1e89827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'a', 'in', 'the', 'on', 'and', 'man', 'is', 'of', 'with', 'woman', 'two', 'are', 'to', 'people', 'at', 'an', 'wearing', 'white', 'young', 'shirt', 'black', 'while', 'his', 'blue', 'red', 'sitting', 'girl', 'men', 'boy', 'standing', 'dog', 'playing', 'street', 'group', 'down', 'front', 'her', 'walking', 'holding', 'one', 'water', 'by', 'three', 'women', 'green', 'up', 'looking', 'child', 'as', 'for', 'little', 'large', 'outside', 'yellow', 'person', 'children', 'brown', 'through', 'hat', 'their', 'from', 'other', 'ball', 'small', 'next', 'into', 'over', 'some', 'dressed', 'out', 'another', 'running', 'building', 'jacket', 'riding', 'around', 'orange', 'near', 'field', 'crowd', 'stands', 'beach', 'background', 'pink', 'sidewalk', 'behind', 'jumping', 'girls', 'table', 'sits', 'grass', 'bike', 'snow', 'that', 'looks', 'top', 'camera', 'air']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.get_vocabulary()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e68432fb-5807-49b1-8491-05614aec79f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1052d70f-c7ff-4ce9-b7dd-cdab3a864a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80,), dtype=int64, numpy=\n",
       "array([  2, 409,   7,  10,  25, 179,   6,   2,  32,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"a tall man with blue t-shirt and a dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ac80c6f-9109-463e-b7c4-88be04f99755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), tokenizer(captions)\n",
    "\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f48fc62f-912b-439e-9344-eb47f14371a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "val_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ec77a96-7a8b-493e-9c0c-abc7c902d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3) (64, 80)\n",
      "(64, 224, 224, 3) (64, 80)\n",
      "(64, 224, 224, 3) (64, 80)\n",
      "(64, 224, 224, 3) (64, 80)\n",
      "(64, 224, 224, 3) (64, 80)\n"
     ]
    }
   ],
   "source": [
    "for img, cap in val_dataset.take(5):\n",
    "    print(img.shape, cap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385b8ff-733d-437a-938f-c66ed6be802c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
