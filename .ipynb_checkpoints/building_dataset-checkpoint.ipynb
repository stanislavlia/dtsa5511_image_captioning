{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf25f0b-1ff7-4858-bd07-90c361698e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 16:24:55.066203: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-10 16:24:55.088885: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082c87ca-9bbd-4d71-b58d-e64df507f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###CONSTANTS\n",
    "# DATA_PATH = \"data/flickr30k_images/\"\n",
    "# IMAGES_PATH = \"data/flickr30k_images/flickr30k_images/\"\n",
    "# IMAGE_SIZE=(224, 224)\n",
    "# VAL_FRACTION=0.05\n",
    "# SEQ_LENGTH=100\n",
    "# BATCH_SIZE=64\n",
    "# EPOCHS=20\n",
    "# AUTOTUNE=tf.data.AUTOTUNE\n",
    "# ###\n",
    "from train_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7013eb-9741-4a79-8a52-c56079932d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Several men in hard hats are operating a gian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Workers look down from up above on a piece of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men working on a machine wearing hard hats .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Four men on top of a tall structure .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Three men on a large rig .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "1  1000092795.jpg              1   \n",
       "2  1000092795.jpg              2   \n",
       "3  1000092795.jpg              3   \n",
       "4  1000092795.jpg              4   \n",
       "5    10002456.jpg              0   \n",
       "6    10002456.jpg              1   \n",
       "7    10002456.jpg              2   \n",
       "8    10002456.jpg              3   \n",
       "9    10002456.jpg              4   \n",
       "\n",
       "                                             comment  \n",
       "0   Two young guys with shaggy hair look at their...  \n",
       "1   Two young , White males are outside near many...  \n",
       "2   Two men in green shirts are standing in a yard .  \n",
       "3       A man in a blue shirt standing in a garden .  \n",
       "4            Two friends enjoy time spent together .  \n",
       "5   Several men in hard hats are operating a gian...  \n",
       "6   Workers look down from up above on a piece of...  \n",
       "7   Two men working on a machine wearing hard hats .  \n",
       "8              Four men on top of a tall structure .  \n",
       "9                         Three men on a large rig .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df = pd.read_csv(os.path.join(DATA_PATH, \"results.csv\"), sep=\"|\")\n",
    "captionings_df.columns = [\"image_name\", \"comment_number\", \"comment\"]\n",
    "captionings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d771d6ce-2273-44f4-b126-075ec2e7d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image-text examples:  150969\n",
      "Validation image-text examples:  7946\n"
     ]
    }
   ],
   "source": [
    "#Shuffle df\n",
    "captionings_df = captionings_df.sample(frac=1,\n",
    "                                       random_state=42,\n",
    "                                       replace=False,\n",
    "                                       )\n",
    "\n",
    "\n",
    "n_train_examples = int(len(captionings_df) * (1 - VAL_FRACTION))\n",
    "\n",
    "train_captionings_df = captionings_df[ : n_train_examples]\n",
    "val_captionings_df = captionings_df[n_train_examples : ]\n",
    "\n",
    "print(\"Train image-text examples: \", train_captionings_df.shape[0])\n",
    "print(\"Validation image-text examples: \", val_captionings_df.shape[0])\n",
    "\n",
    "#save splits\n",
    "train_captionings_df.to_csv(\"splits/train_captions.csv\", index=False)\n",
    "val_captionings_df.to_csv(\"splits/val_captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df08370b-1702-49b0-a088-5daf0d370e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_name', 'comment_number', 'comment'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_captionings_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a0d8b-46e4-487f-a6b5-ee1aad6a5a7c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b00cde8-3dbf-4ba0-a4b2-be49151f08db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import build_tokenizer, build_image_augmenter, process_input, make_dataset, decode_and_resize\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer()\n",
    "tokenizer.adapt(train_captionings_df[\"comment\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae11e236-e0ca-47d0-91de-8a5f1e89827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'a', 'in', 'the', 'on', 'and', 'man', 'is', 'of', 'with', 'woman', 'two', 'are', 'to', 'people', 'at', 'an', 'wearing', 'young', 'white', 'shirt', 'black', 'while', 'his', 'blue', 'red', 'girl', 'sitting', 'men', 'boy', 'dog', 'standing', 'playing', 'street', 'group', 'down', 'front', 'her', 'walking', 'holding', 'one', 'water', 'by', 'three', 'women', 'green', 'up', 'looking', 'child', 'as', 'for', 'little', 'large', 'outside', 'yellow', 'person', 'children', 'brown', 'through', 'from', 'their', 'hat', 'other', 'ball', 'small', 'into', 'next', 'over', 'some', 'dressed', 'out', 'running', 'another', 'building', 'jacket', 'riding', 'around', 'orange', 'near', 'field', 'crowd', 'stands', 'beach', 'background', 'pink', 'sidewalk', 'behind', 'jumping', 'table', 'girls', 'sits', 'grass', 'snow', 'bike', 'that', 'looks', 'top', 'camera', 'air']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.get_vocabulary()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68432fb-5807-49b1-8491-05614aec79f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1052d70f-c7ff-4ce9-b7dd-cdab3a864a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40,), dtype=int64, numpy=\n",
       "array([  2, 407,   7,  10,  25, 185,   6,   2,  31,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"a tall man with blue t-shirt and a dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e19a1-ae85-44e6-9aac-6dad5e833b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac80c6f-9109-463e-b7c4-88be04f99755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), tokenizer(captions)\n",
    "\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4bb8c33-044c-46f1-95af-92bd12495fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
       " array([[[0.00585078, 0.02381562, 0.01875477],\n",
       "         [0.00965832, 0.0196198 , 0.01569823],\n",
       "         [0.0172462 , 0.02443735, 0.01678437],\n",
       "         ...,\n",
       "         [0.7029076 , 0.8511351 , 0.9051871 ],\n",
       "         [0.8868041 , 0.98794574, 1.        ],\n",
       "         [0.8786048 , 0.99592185, 1.        ]],\n",
       " \n",
       "        [[0.00295392, 0.01079705, 0.00687548],\n",
       "         [0.01572215, 0.02356529, 0.01964372],\n",
       "         [0.01424195, 0.02391214, 0.01960394],\n",
       "         ...,\n",
       "         [0.8678015 , 0.9623651 , 0.9731852 ],\n",
       "         [0.62791204, 0.83664644, 0.8352128 ],\n",
       "         [0.8186369 , 0.96124005, 0.9427249 ]],\n",
       " \n",
       "        [[0.03255731, 0.05216515, 0.03647888],\n",
       "         [0.00538098, 0.01640164, 0.00357776],\n",
       "         [0.0212921 , 0.02732662, 0.01683657],\n",
       "         ...,\n",
       "         [0.16157061, 0.35575992, 0.01498929],\n",
       "         [0.11622956, 0.3528709 , 0.02961439],\n",
       "         [0.3335867 , 0.598159  , 0.08154134]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.19922091, 0.25221053, 0.12754281],\n",
       "         [0.12357904, 0.16115032, 0.1104561 ],\n",
       "         [0.13438492, 0.16900896, 0.12050282],\n",
       "         ...,\n",
       "         [0.4874055 , 0.6902661 , 0.3417449 ],\n",
       "         [0.50742733, 0.68684757, 0.44686913],\n",
       "         [0.39998597, 0.5927376 , 0.27179286]],\n",
       " \n",
       "        [[0.28925258, 0.3913832 , 0.22026522],\n",
       "         [0.53782   , 0.64759684, 0.32114297],\n",
       "         [0.56468725, 0.68520325, 0.41769412],\n",
       "         ...,\n",
       "         [0.528848  , 0.6872998 , 0.41468948],\n",
       "         [0.4345186 , 0.5837195 , 0.31522417],\n",
       "         [0.53550166, 0.6737713 , 0.3903345 ]],\n",
       " \n",
       "        [[0.6801512 , 0.7619887 , 0.5011788 ],\n",
       "         [0.6028449 , 0.7194423 , 0.5137476 ],\n",
       "         [0.49589285, 0.72111356, 0.38584447],\n",
       "         ...,\n",
       "         [0.6524411 , 0.7380452 , 0.5420156 ],\n",
       "         [0.6282659 , 0.7438589 , 0.5046874 ],\n",
       "         [0.5622269 , 0.68500036, 0.4075256 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(40,), dtype=int64, numpy=\n",
       " array([ 2,  7, 10,  2, 20, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_input(os.path.join(IMAGES_PATH, \"1000092795.jpg\" ), \"A man with a white dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fc62f-912b-439e-9344-eb47f14371a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
