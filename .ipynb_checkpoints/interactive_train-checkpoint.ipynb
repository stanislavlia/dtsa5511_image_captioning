{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c492f0bd-ff74-4705-9dcc-bd09634aa0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 18:21:46.596563: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 18:21:46.624458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "from train_config import *\n",
    "\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762f9d9c-b04f-410d-99e7-121a209a19c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Two young guys with shaggy hair look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Two young , White males are outside n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men in green shirts are standing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  A man in a blue shirt standing in a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Two friends enjoy time spent together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Several men in hard hats are operatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Workers look down from up above on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men working on a machine wearing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  Four men on top of a tall structure ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Three men on a large rig . &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name comment_number  \\\n",
       "0  data/flickr30k_images/flickr30k_images//100009...              0   \n",
       "1  data/flickr30k_images/flickr30k_images//100009...              1   \n",
       "2  data/flickr30k_images/flickr30k_images//100009...              2   \n",
       "3  data/flickr30k_images/flickr30k_images//100009...              3   \n",
       "4  data/flickr30k_images/flickr30k_images//100009...              4   \n",
       "5  data/flickr30k_images/flickr30k_images//100024...              0   \n",
       "6  data/flickr30k_images/flickr30k_images//100024...              1   \n",
       "7  data/flickr30k_images/flickr30k_images//100024...              2   \n",
       "8  data/flickr30k_images/flickr30k_images//100024...              3   \n",
       "9  data/flickr30k_images/flickr30k_images//100024...              4   \n",
       "\n",
       "                                             comment  \n",
       "0  <START>  Two young guys with shaggy hair look ...  \n",
       "1  <START>  Two young , White males are outside n...  \n",
       "2  <START>  Two men in green shirts are standing ...  \n",
       "3  <START>  A man in a blue shirt standing in a g...  \n",
       "4  <START>  Two friends enjoy time spent together...  \n",
       "5  <START>  Several men in hard hats are operatin...  \n",
       "6  <START>  Workers look down from up above on a ...  \n",
       "7  <START>  Two men working on a machine wearing ...  \n",
       "8  <START>  Four men on top of a tall structure ....  \n",
       "9          <START>  Three men on a large rig . <END>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df = pd.read_csv(os.path.join(DATA_PATH, \"results.csv\"), sep=\"|\").dropna()\n",
    "captionings_df.columns = [\"image_name\", \"comment_number\", \"comment\"]\n",
    "captionings_df[\"image_name\"] = IMAGES_PATH + \"/\" + captionings_df[\"image_name\"] \n",
    "\n",
    "\n",
    "#ADDING START AND END special tokens\n",
    "captionings_df[\"comment\"] = \"<START> \" + captionings_df[\"comment\"] + \" <END>\"\n",
    "captionings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b4e0f7-db62-47e4-a62d-1c3697133cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image-text examples:  150968\n",
      "Validation image-text examples:  7946\n"
     ]
    }
   ],
   "source": [
    "#Shuffle df\n",
    "captionings_df = captionings_df.sample(frac=1,\n",
    "                                       random_state=42,\n",
    "                                       replace=False,\n",
    "                                       )\n",
    "\n",
    "\n",
    "n_train_examples = int(len(captionings_df) * (1 - VAL_FRACTION))\n",
    "\n",
    "train_captionings_df = captionings_df[ : n_train_examples]\n",
    "val_captionings_df = captionings_df[n_train_examples : ]\n",
    "\n",
    "print(\"Train image-text examples: \", train_captionings_df.shape[0])\n",
    "print(\"Validation image-text examples: \", val_captionings_df.shape[0])\n",
    "\n",
    "#save splits\n",
    "train_captionings_df.to_csv(\"splits/train_captions.csv\", index=False)\n",
    "val_captionings_df.to_csv(\"splits/val_captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c3495-4266-4dde-ab22-5a68224c6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 17:54:26.142602: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.162765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.162854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.164932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.165006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.165050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.213689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.213766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.213813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 17:54:26.213852: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:227] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-04-11 17:54:26.213892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13064 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from data_processing import build_tokenizer, build_image_augmenter,  decode_and_resize\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer()\n",
    "tokenizer.adapt(train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), tf.reshape(tokenizer(captions), shape=(1, SEQ_LENGTH))\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af62a91a-b351-4264-869b-76b8c3aeb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "val_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fff3d9-965a-4287-b1c9-7709e54e38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "for img, cap in val_dataset.take(5):\n",
    "    print(img.shape, cap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d75852-aa1d-46ca-997a-a32a7580877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TransformerDecoderBlock, TransformerEncoderBlock, ImageCaptioningModel, get_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6385b918-d10f-4abc-a36c-0a5ae146c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.efficientnet.EfficientNetB1(\n",
    "        input_shape=(*IMAGE_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "    )\n",
    "\n",
    "cnn = get_cnn_model(base_model)\n",
    "\n",
    "encoder = TransformerEncoderBlock(\n",
    "    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=ENC_HEADS\n",
    ")\n",
    "decoder = TransformerDecoderBlock(\n",
    "    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=DEC_HEADS, \n",
    ")\n",
    "\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn,\n",
    "    #image_aug=None,\n",
    "    encoder=encoder, \n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fce7b0-681a-4904-b83f-8935c986e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(train_dataset.take(1))) #SANITY CHECK\n",
    "\n",
    "\n",
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "caption_model.compile(optimizer=keras.optimizers.Adam(0.001), loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea80769-870b-4bd4-8618-592301934bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2359/2359 [==============================] - 324s 138ms/step - loss: 3.5440 - acc: 0.3353 - val_loss: 3.2572 - val_acc: 0.3597\n",
      "Epoch 2/5\n",
      "2359/2359 [==============================] - 319s 135ms/step - loss: 3.4608 - acc: 0.3412 - val_loss: 3.1924 - val_acc: 0.3646\n",
      "Epoch 3/5\n",
      "2359/2359 [==============================] - 329s 140ms/step - loss: 3.4221 - acc: 0.3437 - val_loss: 3.1692 - val_acc: 0.3643\n",
      "Epoch 4/5\n",
      "   6/2359 [..............................] - ETA: 2:51 - loss: 3.4547 - acc: 0.3495"
     ]
    }
   ],
   "source": [
    "caption_model.fit(train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b411030-7c0c-48e1-9538-acdd5ff2dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "caption_model.save_weights(\"caption_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e046ff3-49a2-48f5-9686-5146b7b48c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from training_utils import load_trained_model_weights\n",
    "\n",
    "\n",
    "\n",
    "new_model = load_trained_model_weights(\"caption_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535f85ce-115e-4529-b5f6-8ead5198af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"image_captioning_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_1 (Functional)        (None, 49, 1280)          6575239   \n",
      "                                                                 \n",
      " transformer_encoder_block_  multiple                  1710080   \n",
      " 1 (TransformerEncoderBlock                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_decoder_block_  multiple                  14733840  \n",
      " 1 (TransformerDecoderBlock                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23019163 (87.81 MB)\n",
      "Trainable params: 16443920 (62.73 MB)\n",
      "Non-trainable params: 6575243 (25.08 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bbf716-bee6-4b7e-b9b3-d7a01d6e3f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 31ms/step - loss: 3.3813 - acc: 0.3619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3812708854675293, 0.37292519211769104]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.compile(optimizer=keras.optimizers.Adam(0.001), loss=cross_entropy)\n",
    "\n",
    "new_model.evaluate(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd30721-0470-46b7-8212-0352b6b2c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20807c58-f85b-4c4c-a56b-2799702a083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10619"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e093c-0b67-4994-81bf-53d0e900ca0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
