{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c492f0bd-ff74-4705-9dcc-bd09634aa0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:09:04.797598: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 16:09:04.821027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "from train_config import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762f9d9c-b04f-410d-99e7-121a209a19c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Two young guys with shaggy hair look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Two young , White males are outside n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men in green shirts are standing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  A man in a blue shirt standing in a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Two friends enjoy time spent together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Several men in hard hats are operatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Workers look down from up above on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men working on a machine wearing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  Four men on top of a tall structure ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Three men on a large rig . &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name comment_number  \\\n",
       "0  data/flickr30k_images/flickr30k_images//100009...              0   \n",
       "1  data/flickr30k_images/flickr30k_images//100009...              1   \n",
       "2  data/flickr30k_images/flickr30k_images//100009...              2   \n",
       "3  data/flickr30k_images/flickr30k_images//100009...              3   \n",
       "4  data/flickr30k_images/flickr30k_images//100009...              4   \n",
       "5  data/flickr30k_images/flickr30k_images//100024...              0   \n",
       "6  data/flickr30k_images/flickr30k_images//100024...              1   \n",
       "7  data/flickr30k_images/flickr30k_images//100024...              2   \n",
       "8  data/flickr30k_images/flickr30k_images//100024...              3   \n",
       "9  data/flickr30k_images/flickr30k_images//100024...              4   \n",
       "\n",
       "                                             comment  \n",
       "0  <START>  Two young guys with shaggy hair look ...  \n",
       "1  <START>  Two young , White males are outside n...  \n",
       "2  <START>  Two men in green shirts are standing ...  \n",
       "3  <START>  A man in a blue shirt standing in a g...  \n",
       "4  <START>  Two friends enjoy time spent together...  \n",
       "5  <START>  Several men in hard hats are operatin...  \n",
       "6  <START>  Workers look down from up above on a ...  \n",
       "7  <START>  Two men working on a machine wearing ...  \n",
       "8  <START>  Four men on top of a tall structure ....  \n",
       "9          <START>  Three men on a large rig . <END>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df = pd.read_csv(os.path.join(DATA_PATH, \"results.csv\"), sep=\"|\").dropna()\n",
    "captionings_df.columns = [\"image_name\", \"comment_number\", \"comment\"]\n",
    "captionings_df[\"image_name\"] = IMAGES_PATH + \"/\" + captionings_df[\"image_name\"] \n",
    "\n",
    "\n",
    "#ADDING START AND END special tokens\n",
    "captionings_df[\"comment\"] = \"<START> \" + captionings_df[\"comment\"] + \" <END>\"\n",
    "captionings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b4e0f7-db62-47e4-a62d-1c3697133cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image-text examples:  150968\n",
      "Validation image-text examples:  7946\n"
     ]
    }
   ],
   "source": [
    "#Shuffle df\n",
    "captionings_df = captionings_df.sample(frac=1,\n",
    "                                       random_state=42,\n",
    "                                       replace=False,\n",
    "                                       )\n",
    "\n",
    "\n",
    "n_train_examples = int(len(captionings_df) * (1 - VAL_FRACTION))\n",
    "\n",
    "train_captionings_df = captionings_df[ : n_train_examples]\n",
    "val_captionings_df = captionings_df[n_train_examples : ]\n",
    "\n",
    "print(\"Train image-text examples: \", train_captionings_df.shape[0])\n",
    "print(\"Validation image-text examples: \", val_captionings_df.shape[0])\n",
    "\n",
    "#save splits\n",
    "train_captionings_df.to_csv(\"splits/train_captions.csv\", index=False)\n",
    "val_captionings_df.to_csv(\"splits/val_captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c3495-4266-4dde-ab22-5a68224c6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:09:07.951750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:07.971647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:07.971727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:07.973951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:07.974016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:07.974059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:08.021358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:08.021436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:08.021481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:09:08.021546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1105 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from data_processing import build_tokenizer, build_image_augmenter,  decode_and_resize\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer()\n",
    "tokenizer.adapt(train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), tf.reshape(tokenizer(captions), shape=(1, SEQ_LENGTH))\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af62a91a-b351-4264-869b-76b8c3aeb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "val_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fff3d9-965a-4287-b1c9-7709e54e38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "for img, cap in val_dataset.take(5):\n",
    "    print(img.shape, cap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d75852-aa1d-46ca-997a-a32a7580877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TransformerDecoderBlock, TransformerEncoderBlock, ImageCaptioningModel, get_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6385b918-d10f-4abc-a36c-0a5ae146c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.efficientnet.EfficientNetB1(\n",
    "        input_shape=(*IMAGE_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "    )\n",
    "\n",
    "cnn = get_cnn_model(base_model)\n",
    "\n",
    "encoder = TransformerEncoderBlock(\n",
    "    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1\n",
    ")\n",
    "decoder = TransformerDecoderBlock(\n",
    "    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2, \n",
    ")\n",
    "\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn,\n",
    "    #image_aug=None,\n",
    "    encoder=encoder, \n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3fce7b0-681a-4904-b83f-8935c986e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(train_dataset.take(1))) #SANITY CHECK\n",
    "\n",
    "\n",
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "caption_model.compile(optimizer=keras.optimizers.Adam(0.01), loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea80769-870b-4bd4-8618-592301934bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:11:24.559458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-04-11 16:11:24.571112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-04-11 16:11:24.754642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x76db7e5ba6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-11 16:11:24.754660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090 Laptop GPU, Compute Capability 8.9\n",
      "2024-04-11 16:11:24.757260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-11 16:11:24.817253: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 114ms/step - loss: 8.3739 - acc: 0.0670\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.1193 - acc: 0.1180\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 7.7537 - acc: 0.0552\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 6.4352 - acc: 0.0083\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 5.6851 - acc: 0.0838\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 5.8693 - acc: 0.1227\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 5.7554 - acc: 0.1000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 5.6492 - acc: 0.0625\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 5.3309 - acc: 0.0861\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 5.2502 - acc: 0.1148\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 5.2432 - acc: 0.1233\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 5.1593 - acc: 0.1093\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.0934 - acc: 0.0869\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 5.0752 - acc: 0.0820\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.0456 - acc: 0.1130\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.9794 - acc: 0.1223\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.9845 - acc: 0.1297\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.9569 - acc: 0.1185\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.9484 - acc: 0.1093\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.9772 - acc: 0.1091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x76defc2dca00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_model.fit(X_batch, y_batch, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b411030-7c0c-48e1-9538-acdd5ff2dc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
