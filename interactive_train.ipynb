{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c492f0bd-ff74-4705-9dcc-bd09634aa0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:55:44.321316: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 16:55:44.344526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "from train_config import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762f9d9c-b04f-410d-99e7-121a209a19c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Two young guys with shaggy hair look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Two young , White males are outside n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men in green shirts are standing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  A man in a blue shirt standing in a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100009...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Two friends enjoy time spent together...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;START&gt;  Several men in hard hats are operatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;START&gt;  Workers look down from up above on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;START&gt;  Two men working on a machine wearing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;START&gt;  Four men on top of a tall structure ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/flickr30k_images/flickr30k_images//100024...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;START&gt;  Three men on a large rig . &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name comment_number  \\\n",
       "0  data/flickr30k_images/flickr30k_images//100009...              0   \n",
       "1  data/flickr30k_images/flickr30k_images//100009...              1   \n",
       "2  data/flickr30k_images/flickr30k_images//100009...              2   \n",
       "3  data/flickr30k_images/flickr30k_images//100009...              3   \n",
       "4  data/flickr30k_images/flickr30k_images//100009...              4   \n",
       "5  data/flickr30k_images/flickr30k_images//100024...              0   \n",
       "6  data/flickr30k_images/flickr30k_images//100024...              1   \n",
       "7  data/flickr30k_images/flickr30k_images//100024...              2   \n",
       "8  data/flickr30k_images/flickr30k_images//100024...              3   \n",
       "9  data/flickr30k_images/flickr30k_images//100024...              4   \n",
       "\n",
       "                                             comment  \n",
       "0  <START>  Two young guys with shaggy hair look ...  \n",
       "1  <START>  Two young , White males are outside n...  \n",
       "2  <START>  Two men in green shirts are standing ...  \n",
       "3  <START>  A man in a blue shirt standing in a g...  \n",
       "4  <START>  Two friends enjoy time spent together...  \n",
       "5  <START>  Several men in hard hats are operatin...  \n",
       "6  <START>  Workers look down from up above on a ...  \n",
       "7  <START>  Two men working on a machine wearing ...  \n",
       "8  <START>  Four men on top of a tall structure ....  \n",
       "9          <START>  Three men on a large rig . <END>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionings_df = pd.read_csv(os.path.join(DATA_PATH, \"results.csv\"), sep=\"|\").dropna()\n",
    "captionings_df.columns = [\"image_name\", \"comment_number\", \"comment\"]\n",
    "captionings_df[\"image_name\"] = IMAGES_PATH + \"/\" + captionings_df[\"image_name\"] \n",
    "\n",
    "\n",
    "#ADDING START AND END special tokens\n",
    "captionings_df[\"comment\"] = \"<START> \" + captionings_df[\"comment\"] + \" <END>\"\n",
    "captionings_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b4e0f7-db62-47e4-a62d-1c3697133cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image-text examples:  150968\n",
      "Validation image-text examples:  7946\n"
     ]
    }
   ],
   "source": [
    "#Shuffle df\n",
    "captionings_df = captionings_df.sample(frac=1,\n",
    "                                       random_state=42,\n",
    "                                       replace=False,\n",
    "                                       )\n",
    "\n",
    "\n",
    "n_train_examples = int(len(captionings_df) * (1 - VAL_FRACTION))\n",
    "\n",
    "train_captionings_df = captionings_df[ : n_train_examples]\n",
    "val_captionings_df = captionings_df[n_train_examples : ]\n",
    "\n",
    "print(\"Train image-text examples: \", train_captionings_df.shape[0])\n",
    "print(\"Validation image-text examples: \", val_captionings_df.shape[0])\n",
    "\n",
    "#save splits\n",
    "train_captionings_df.to_csv(\"splits/train_captions.csv\", index=False)\n",
    "val_captionings_df.to_csv(\"splits/val_captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c3495-4266-4dde-ab22-5a68224c6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:55:50.767499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.787030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.787142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.789969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.790172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.790215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.846621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.846702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.846749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-11 16:55:50.846800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1208 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from data_processing import build_tokenizer, build_image_augmenter,  decode_and_resize\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer()\n",
    "tokenizer.adapt(train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), tf.reshape(tokenizer(captions), shape=(1, SEQ_LENGTH))\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af62a91a-b351-4264-869b-76b8c3aeb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n",
    "\n",
    "val_dataset = make_dataset(train_captionings_df[\"image_name\"].tolist(),\n",
    "                             train_captionings_df[\"comment\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fff3d9-965a-4287-b1c9-7709e54e38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n",
      "(64, 224, 224, 3) (64, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "for img, cap in val_dataset.take(5):\n",
    "    print(img.shape, cap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d75852-aa1d-46ca-997a-a32a7580877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TransformerDecoderBlock, TransformerEncoderBlock, ImageCaptioningModel, get_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6385b918-d10f-4abc-a36c-0a5ae146c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.efficientnet.EfficientNetB1(\n",
    "        input_shape=(*IMAGE_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "    )\n",
    "\n",
    "cnn = get_cnn_model(base_model)\n",
    "\n",
    "encoder = TransformerEncoderBlock(\n",
    "    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=ENC_HEADS\n",
    ")\n",
    "decoder = TransformerDecoderBlock(\n",
    "    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=DEC_HEADS, \n",
    ")\n",
    "\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn,\n",
    "    #image_aug=None,\n",
    "    encoder=encoder, \n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fce7b0-681a-4904-b83f-8935c986e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(train_dataset.take(1))) #SANITY CHECK\n",
    "\n",
    "\n",
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "caption_model.compile(optimizer=keras.optimizers.Adam(0.001), loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea80769-870b-4bd4-8618-592301934bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:56:01.291202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-04-11 16:56:01.454853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-04-11 16:56:01.513172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eb276af4dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-11 16:56:01.513189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090 Laptop GPU, Compute Capability 8.9\n",
      "2024-04-11 16:56:01.515818: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-11 16:56:01.578600: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 106ms/step - loss: 9.0403 - acc: 0.0319\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 7.6846 - acc: 0.1226\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 6.6065 - acc: 0.1214\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 5.6611 - acc: 0.1372\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 5.1438 - acc: 0.1706\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.7115 - acc: 0.2013\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 4.3553 - acc: 0.2057\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 4.4964 - acc: 0.2482\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.4660 - acc: 0.2092\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.4568 - acc: 0.2184\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.2788 - acc: 0.2169\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 4.0710 - acc: 0.2167\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.6818 - acc: 0.2641\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 3.2816 - acc: 0.3631\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 3.0469 - acc: 0.4009\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8525 - acc: 0.4466\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 2.6152 - acc: 0.5312\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.3921 - acc: 0.5502\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 2.1925 - acc: 0.5783\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.9937 - acc: 0.6071\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.8265 - acc: 0.6134\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.7008 - acc: 0.6550\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.5358 - acc: 0.6928\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.4317 - acc: 0.7087\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3193 - acc: 0.7294\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.2191 - acc: 0.7557\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1575 - acc: 0.7761\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0730 - acc: 0.7818\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0132 - acc: 0.7831\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9269 - acc: 0.8073\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8994 - acc: 0.7856\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8672 - acc: 0.7884\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7983 - acc: 0.8162\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7440 - acc: 0.8241\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7360 - acc: 0.8099\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7118 - acc: 0.8104\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6773 - acc: 0.8135\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6703 - acc: 0.8214\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6374 - acc: 0.8322\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6132 - acc: 0.8279\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6156 - acc: 0.8271\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5601 - acc: 0.8519\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5784 - acc: 0.8421\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5602 - acc: 0.8523\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5367 - acc: 0.8518\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5485 - acc: 0.8453\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5356 - acc: 0.8343\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5318 - acc: 0.8473\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5199 - acc: 0.8573\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5064 - acc: 0.8576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eb620cdc610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_model.fit(X_batch, y_batch, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b411030-7c0c-48e1-9538-acdd5ff2dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "caption_model.save_weights(\"caption_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e046ff3-49a2-48f5-9686-5146b7b48c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from training_utils import load_trained_model_weights\n",
    "\n",
    "\n",
    "\n",
    "new_model = load_trained_model_weights(\"caption_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535f85ce-115e-4529-b5f6-8ead5198af5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"image_captioning_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_1 (Functional)        (None, 49, 1280)          6575239   \n",
      "                                                                 \n",
      " transformer_encoder_block_  multiple                  1710080   \n",
      " 1 (TransformerEncoderBlock                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_decoder_block_  multiple                  14733840  \n",
      " 1 (TransformerDecoderBlock                                      \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23019163 (87.81 MB)\n",
      "Trainable params: 16443920 (62.73 MB)\n",
      "Non-trainable params: 6575243 (25.08 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbf716-bee6-4b7e-b9b3-d7a01d6e3f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
